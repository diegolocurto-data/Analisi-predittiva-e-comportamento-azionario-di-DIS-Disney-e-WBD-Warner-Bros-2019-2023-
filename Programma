import numpy as np 
import pandas as pd 
import yfinance as yf 
import matplotlib.pyplot as plt 
import seaborn as sns 
import joblib 
from sklearn.ensemble import RandomForestRegressor 
from sklearn.cluster import KMeans 
from sklearn.linear_model import LinearRegression 
from sklearn.metrics import mean_squared_error, r2_score, confusion_matrix 
from sklearn.preprocessing import StandardScaler 
from sklearn.model_selection import train_test_split, GridSearchCV 
# Download dei dati  
dis = yf.download('DIS', start='2019-01-01', end='2023-12-31') 
wbd = yf.download('WBD', start='2019-01-01', end='2023-12-31') 
# Estrazione prezzo di chiusura 
dis_price = dis[['Close']].squeeze() 
wbd_price = wbd[['Close']].squeeze() 
# Allineamento temporale 
wbd_price = wbd_price.reindex(dis_price.index) 
# DataFrame 
data = pd.DataFrame({'DIS_Close': dis_price, 'WBD_Close': wbd_price}) 
data.interpolate(method='linear', inplace=True) 
# Feature lag 
for col in data.columns: 
for lag in range(1, 6): 
data[f'{col}_lag{lag}'] = data[col].shift(lag) 
data.dropna(inplace=True) 
# Normalizzazione 
scaler = StandardScaler() 
data_scaled = scaler.fit_transform(data[['DIS_Close', 'WBD_Close']]) 
# Clustering 
kmeans = KMeans(n_clusters=3, random_state=42, n_init=10) 
clusters = kmeans.fit_predict(data_scaled) 
data['Cluster'] = clusters 
# Split 
train = data[data.index < '2023-01-01'] 
test = data[data.index >= '2023-01-01'] 
X_train = train.drop(columns=['DIS_Close', 'WBD_Close']) 
X_test = test.drop(columns=['DIS_Close', 'WBD_Close']) 
y_train_dis = train['DIS_Close'] 
y_test_dis = test['DIS_Close'] 
y_train_wbd = train['WBD_Close'] 
y_test_wbd = test['WBD_Close'] 
# Random Forest DIS 
rf_dis = RandomForestRegressor(n_estimators=500, random_state=42) 
rf_dis.fit(X_train, y_train_dis) 
y_pred_dis = rf_dis.predict(X_test) 
# Random Forest WBD 
rf_wbd = RandomForestRegressor(n_estimators=500, random_state=42) 
rf_wbd.fit(X_train, y_train_wbd) 
y_pred_wbd = rf_wbd.predict(X_test) 
# Valutazione RF 
rmse_dis = mean_squared_error(y_test_dis, y_pred_dis) ** 0.5 
r2_dis = r2_score(y_test_dis, y_pred_dis) 
rmse_wbd = mean_squared_error(y_test_wbd, y_pred_wbd) ** 0.5 
r2_wbd = r2_score(y_test_wbd, y_pred_wbd) 
print(f"Random Forest - RMSE DIS: {rmse_dis:.2f}, R^2: {r2_dis:.2f}") 
print(f"Random Forest - RMSE WBD: {rmse_wbd:.2f}, R^2: {r2_wbd:.2f}") 
# Regressione Lineare DIS 
lr = LinearRegression() 
lr.fit(X_train, y_train_dis) 
y_pred_lr = lr.predict(X_test) 
rmse_lr = mean_squared_error(y_test_dis, y_pred_lr) ** 0.5 
r2_lr = r2_score(y_test_dis, y_pred_lr) 
print(f"Linear Regression - RMSE DIS: {rmse_lr:.2f}, R^2: {r2_lr:.2f}") 
# Importanza feature DIS 
importances = rf_dis.feature_importances_ 
features = X_train.columns 
plt.figure(figsize=(10,6)) 
sns.barplot(x=importances, y=features) 
plt.title('Importanza delle feature - Random Forest DIS') 
plt.show() 
# Analisi degli errori DIS 
errors = y_test_dis - y_pred_dis 
plt.figure(figsize=(8,4)) 
sns.histplot(errors, kde=True) 
plt.title('Distribuzione degli errori - DIS') 
plt.xlabel('Errore') 
plt.show() 
# Metodo del gomito 
inertia = [] 
for k in range(1, 10): 
kmeans = KMeans(n_clusters=k, random_state=42, n_init=10) 
kmeans.fit(data_scaled) 
inertia.append(kmeans.inertia_) 
plt.figure(figsize=(8,5)) 
plt.plot(range(1, 10), inertia, marker='o') 
plt.xlabel('Numero di Cluster') 
plt.ylabel('Inertia') 
plt.title('Metodo del Gomito') 
plt.show() 
# Matrice di confusione 
conf_matrix = confusion_matrix(data['Cluster'], clusters) 
print('Matrice di confusione:\n', conf_matrix) 
# Correlazione 
corr_matrix = data[['DIS_Close', 'WBD_Close']].corr() 
plt.figure(figsize=(6,4)) 
sns.heatmap(corr_matrix, annot=True, cmap='coolwarm', fmt='.2f') 
plt.title('Matrice di correlazione DIS/WBD') 
plt.show() 
# Previsioni DIS 
plt.figure(figsize=(12,5)) 
plt.plot(test.index, y_test_dis, label='DIS Reale') 
plt.plot(test.index, y_pred_dis, label='DIS Predetto', linestyle='dashed') 
plt.plot(test.index, y_pred_lr, label='DIS Regressione Lineare', linestyle='dotted') 
plt.legend() 
plt.title('Previsioni DIS: RF vs LR') 
plt.show() 
# Previsioni WBD 
plt.figure(figsize=(12,5)) 
plt.plot(test.index, y_test_wbd, label='WBD Reale') 
plt.plot(test.index, y_pred_wbd, label='WBD Predetto', linestyle='dashed') 
plt.legend() 
plt.title('Previsione Random Forest per WBD') 
plt.show() 
# Analisi rendimenti mensili 
monthly_returns = data[['DIS_Close', 'WBD_Close']].resample('M').ffill().pct_change() 
monthly_returns.plot(figsize=(10,5), title='Rendimenti mensili %') 
plt.show() 
# GridSearchCV per ottimizzare Random Forest DIS 
param_grid = {'n_estimators': [100, 300, 500], 'max_depth': [None, 10, 20]} 
grid = GridSearchCV(RandomForestRegressor(random_state=42), param_grid, cv=3) 
grid.fit(X_train, y_train_dis) 
print("Migliori parametri trovati da GridSearch:", grid.best_params_) 
# Salvataggio modello 
joblib.dump(rf_dis, 'random_forest_dis.pkl') 
